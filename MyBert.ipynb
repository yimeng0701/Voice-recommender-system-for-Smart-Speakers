{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyBert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZJw_4J1OCeV",
        "colab_type": "code",
        "outputId": "071f8b43-fca5-4b26-99cc-6c55d570ad5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcxepLSfOCdp",
        "colab_type": "code",
        "outputId": "65cb4ed1-dfb4-436d-ae55-52ab6a1eba2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fu1i8LWr-Kc",
        "colab_type": "code",
        "outputId": "18b4bc05-0d14-457d-c1bb-2d968b55de43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjAu7cs1sIv8",
        "colab_type": "code",
        "outputId": "7f7c00eb-df3a-4f41-b11d-7fb27f0b59fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 19 08:35:44 2019\n",
        "\n",
        "@author: prettyyang2\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import bert\n",
        "#from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "from bert import modeling\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "path = '/gdrive/My Drive/insight_project'\n",
        "\n",
        "##use downloaded model: base_bert; uncased\n",
        "\n",
        "BERT_VOCAB= os.path.join(path,'uncased_L-12_H-768_A-12/vocab.txt') \n",
        "BERT_INIT_CHKPNT = os.path.join(path,'uncased_L-12_H-768_A-12/bert_model.ckpt') \n",
        "BERT_CONFIG =os.path.join(path,'uncased_L-12_H-768_A-12/bert_config.json') \n",
        "\n",
        "##hperparameters\n",
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 100.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "\n",
        "def _read_tsv(input_file, quotechar=None):\n",
        "    \"\"\"Reads a tab separated value file.\"\"\"\n",
        "    with tf.gfile.Open(input_file, \"r\") as f:\n",
        "      reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "      lines = []\n",
        "      for line in reader:\n",
        "        lines.append(line)\n",
        "      return lines\n",
        "\n",
        "def Multi_hot_label(labels, label_list):\n",
        "    \"\"\" change the labels to multi_hot encoding\n",
        "    labels: list  i.e. ['a'] or ['a','b']\n",
        "    label_list: list\n",
        "    \"\"\"\n",
        "    n = len(label_list) \n",
        "    ans = [0]*n\n",
        "    for i in range(n):\n",
        "        if label_list[i] in labels:\n",
        "            ans[i] = 1\n",
        "    return ans\n",
        "            \n",
        "tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
        "tokenizer = tokenization.FullTokenizer( vocab_file=BERT_VOCAB, do_lower_case=True)\n",
        "\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, is_real_example=True):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids,\n",
        "        self.is_real_example=is_real_example\n",
        "        \n",
        "def create_examples(data, label_list, set_type, labels_available=True):\n",
        "    \"\"\"Creates examples for the training, dev and test sets.\n",
        "       Data:list\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(data):        \n",
        "        guid = \"%s\" % (i)\n",
        "        text_a = tokenization.convert_to_unicode(line[1].strip(\"\\n\"))\n",
        "        if labels_available:\n",
        "            labels = tokenization.convert_to_unicode(line[0])\n",
        "            labels = labels.split(\", \")   #format: list  ['a'] or ['a','b']\n",
        "            labels = Multi_hot_label(labels,label_list)\n",
        "        else:\n",
        "            labels = [0]*len(label_list)\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "    return examples\n",
        "\n",
        "def convert_examples_to_features(examples,  max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        print(example.text_a)\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(int(label))\n",
        "\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features\n",
        "  \n",
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "    When running eval/predict on the TPU, we need to pad the number of examples\n",
        "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "    size. The alternative is to drop the last batch, which is bad because it means\n",
        "    the entire output data won't be generated.\n",
        "    We use this class instead of `None` because treating `None` as padding\n",
        "    battches could cause silent errors.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "def convert_single_example(ex_index, example, max_seq_length,\n",
        "                           tokenizer):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        return InputFeatures(\n",
        "            input_ids=[0] * max_seq_length,\n",
        "            input_mask=[0] * max_seq_length,\n",
        "            segment_ids=[0] * max_seq_length,\n",
        "            label_ids=0,\n",
        "            is_real_example=False)\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids: 0     0   0   0  0     0 0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "            segment_ids.append(1)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        segment_ids.append(1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "    \n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    labels_ids = []\n",
        "    for label in example.labels:\n",
        "        labels_ids.append(int(label))\n",
        "\n",
        "\n",
        "    feature = InputFeatures(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        label_ids=labels_ids,\n",
        "        is_real_example=True)\n",
        "    return feature\n",
        "  \n",
        "def file_based_convert_examples_to_features(\n",
        "        examples, max_seq_length, tokenizer, output_file):\n",
        "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        #if ex_index % 10000 == 0:\n",
        "            #tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        feature = convert_single_example(ex_index, example,\n",
        "                                         max_seq_length, tokenizer)\n",
        "\n",
        "        def create_int_feature(values):\n",
        "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
        "            return f\n",
        "\n",
        "        features = collections.OrderedDict()\n",
        "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "        features[\"is_real_example\"] = create_int_feature(\n",
        "            [int(feature.is_real_example)])\n",
        "        if isinstance(feature.label_ids, list):\n",
        "            label_ids = feature.label_ids\n",
        "        else:\n",
        "            label_ids = feature.label_ids[0]\n",
        "        features[\"label_ids\"] = create_int_feature(label_ids)\n",
        "\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()\n",
        "    \n",
        "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
        "                                drop_remainder, num_class):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "    name_to_features = {\n",
        "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"label_ids\": tf.FixedLenFeature([num_class], tf.int64),\n",
        "        \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.to_int32(t)\n",
        "            example[name] = t\n",
        "\n",
        "        return example\n",
        "      \n",
        "    def input_fn(params):\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "        batch_size = params[\"batch_size\"]\n",
        "\n",
        "        # For training, we want a lot of parallel reading and shuffling.\n",
        "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            d = d.shuffle(buffer_size=100)\n",
        "\n",
        "        d = d.apply(\n",
        "            tf.contrib.data.map_and_batch(\n",
        "                lambda record: _decode_record(record, name_to_features),\n",
        "                batch_size=batch_size,\n",
        "                drop_remainder=drop_remainder))\n",
        "\n",
        "        return d\n",
        "\n",
        "    return input_fn\n",
        "  \n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "            \n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    # In the demo, we are doing a simple classification task on the entire\n",
        "    # segment.\n",
        "    #\n",
        "    # If you want to use the token-level output, use model.get_sequence_output()\n",
        "    # instead.\n",
        "    output_layer = model.get_pooled_output()\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\", [num_labels, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        if is_training:\n",
        "            # I.e., 0.1 dropout\n",
        "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        \n",
        "        # probabilities = tf.nn.softmax(logits, axis=-1) ### multiclass case\n",
        "        probabilities = tf.nn.sigmoid(logits)#### multi-label case\n",
        "        \n",
        "        labels = tf.cast(labels, tf.float32)\n",
        "        tf.logging.info(\"num_labels:{};logits:{};labels:{}\".format(num_labels, logits, labels))\n",
        "        per_example_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "        # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "        # log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "        #\n",
        "        # one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "        #\n",
        "        # per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        # loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "        return (loss, per_example_loss, logits, probabilities)\n",
        "      \n",
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        tf.logging.info(\"*** Features ***\")\n",
        "        for name in sorted(features.keys()):\n",
        "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "        is_real_example = None\n",
        "        if \"is_real_example\" in features:\n",
        "             is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "        else:\n",
        "             is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "            num_labels, use_one_hot_embeddings)\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        initialized_variable_names = {}\n",
        "        scaffold_fn = None\n",
        "        if init_checkpoint:\n",
        "            (assignment_map, initialized_variable_names\n",
        "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "            if use_tpu:\n",
        "\n",
        "                def tpu_scaffold():\n",
        "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "                    return tf.train.Scaffold()\n",
        "\n",
        "                scaffold_fn = tpu_scaffold\n",
        "            else:\n",
        "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "        tf.logging.info(\"**** Trainable Variables ****\")\n",
        "        for var in tvars:\n",
        "            init_string = \"\"\n",
        "            if var.name in initialized_variable_names:\n",
        "                init_string = \", *INIT_FROM_CKPT*\"\n",
        "            #tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,init_string)\n",
        "\n",
        "        output_spec = None\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "            train_op = optimization.create_optimizer(\n",
        "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                train_op=train_op,\n",
        "                scaffold=scaffold_fn)\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "            def metric_fn(per_example_loss, label_ids, probabilities, is_real_example):\n",
        "\n",
        "                logits_split = tf.split(probabilities, num_labels, axis=-1)\n",
        "                label_ids_split = tf.split(label_ids, num_labels, axis=-1)\n",
        "                # metrics change to auc of every class\n",
        "                eval_dict = {}\n",
        "                for j, logits in enumerate(logits_split):\n",
        "                    label_id_ = tf.cast(label_ids_split[j], dtype=tf.int32)\n",
        "                    current_auc, update_op_auc = tf.metrics.auc(label_id_, logits)\n",
        "                    eval_dict[str(j)] = (current_auc, update_op_auc)\n",
        "                eval_dict['eval_loss'] = tf.metrics.mean(values=per_example_loss)\n",
        "                return eval_dict\n",
        "\n",
        "                ## original eval metrics\n",
        "                # predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "                # accuracy = tf.metrics.accuracy(\n",
        "                #     labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "                # loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "                # return {\n",
        "                #     \"eval_accuracy\": accuracy,\n",
        "                #     \"eval_loss\": loss,\n",
        "                # }\n",
        "\n",
        "            eval_metrics = metric_fn(per_example_loss, label_ids, probabilities, is_real_example)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                eval_metric_ops=eval_metrics,\n",
        "                scaffold=scaffold_fn)\n",
        "        else:\n",
        "            print(\"mode:\", mode,\"probabilities:\", probabilities)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                predictions={\"probabilities\": probabilities},\n",
        "                scaffold=scaffold_fn)\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn      \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  label_list =  _read_tsv(os.path.join(path,'data/label_list.tsv'))[0]\n",
        "  \n",
        "  data = _read_tsv(os.path.join(path,'data/data.tsv'))\n",
        "  \n",
        "  train_data, test_data = train_test_split(data, test_size=0.2)\n",
        "  train_examples = create_examples(train_data,label_list,'train')\n",
        "  #test_examples = create_examples(test_data,label_list,'test',False)\n",
        "  \n",
        "  # Compute # train and warmup steps from batch size\n",
        "  num_train_steps = int(len(train_examples) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "  \n",
        "  train_file = \"./working/train.tf_record\"\n",
        "  #filename = Path(train_file)\n",
        "  if not os.path.exists(os.path.join(path,train_file)):\n",
        "      open(train_file, 'w').close()\n",
        "\n",
        "      \n",
        "  file_based_convert_examples_to_features(\n",
        "            train_examples, MAX_SEQ_LENGTH, tokenizer, train_file)\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "  tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  \n",
        "  train_input_fn = file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False, num_class = len(label_list))\n",
        "  \n",
        "  OUTPUT_DIR =  os.path.join(path,'working/output')\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      model_dir=OUTPUT_DIR,\n",
        "      save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "      keep_checkpoint_max=1,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "  \n",
        "  bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "  model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels= len(label_list),\n",
        "    init_checkpoint=BERT_INIT_CHKPNT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=False,\n",
        "    use_one_hot_embeddings=False)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    params={\"batch_size\": BATCH_SIZE})\n",
        "  \n",
        "  print(f'Beginning Training!')\n",
        "  current_time = datetime.now()\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print(\"Training took time \", datetime.now() - current_time)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 140\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 437\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/gdrive/My Drive/insight_project/working/output', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d40d302e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "Beginning Training!\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
            "Training took time  0:00:00.014430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNRhut28ErJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f476e456-c55a-4f1e-905a-ab41d1b1f4f0"
      },
      "source": [
        "#evaluation\n",
        "\n",
        "eval_file =  \"./working/eval.tf_record\"\n",
        "#filename = Path(train_file)\n",
        "if not os.path.exists(os.path.join(path,eval_file)):\n",
        "    open(eval_file, 'w').close()\n",
        "\n",
        "file_based_convert_examples_to_features(\n",
        "    dev_examples, MAX_SEQ_LENGTH, tokenizer, eval_file)\n",
        "\n",
        "#This tells the estimator to run through the entire set.\n",
        "eval_steps = None\n",
        "\n",
        "eval_drop_remainder = False\n",
        "eval_input_fn = file_based_input_fn_builder(\n",
        "    input_file=eval_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "\n",
        "output_eval_file = os.path.join(\"./working\", \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    tf.logging.info(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3fd99763f70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m file_based_convert_examples_to_features(\n\u001b[0;32m----> 7\u001b[0;31m     dev_examples, MAX_SEQ_LENGTH, tokenizer, eval_file)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dev_examples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyA2B1u9HxUB",
        "colab_type": "code",
        "outputId": "b45ff30e-8e17-4107-8df3-5774ef846793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "#prediction\n",
        "\n",
        "predict_examples = create_examples(test_data,'test',False)\n",
        "test_features = convert_examples_to_features(predict_examples, MAX_SEQ_LENGTH, tokenizer)\n",
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_ids)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples, len(label_list)], dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are some useful definitions of terms you'll come across in election coverage.Advance polls — During specific times and days before election day, polls are opened for people who want to vote early. The ballots are not counted until election day.Attack ad — A negative ad that criticizes a political candidate. These ads are paid for by opposing political parties, or by third-party groups. Ballot — The piece of paper on which electors mark a vote for a candidate. Candidates are listed in alphabetical order on the ballot. The ballot also includes information about each candidate's political party, or if the candidate has registered as an independent. See also: special ballot.Canada Elections Act — The law that regulates federal elections. Commissioner of Canada Elections — An independent officer who investigates violations of the Canada Elections Act and the Referendum Act. The commissioner is independent of Elections Canada, however the commissioner is appointed to a 10-year term by the Chief Electoral Officer. The commissioner can't have been a candidate or have worked for a political party, either as an employee or contractor. Chief electoral officer — Person responsible for overseeing federal elections in Canada. This person is considered an independent agent of Parliament. Debate consortium — A group of broadcasters that agree to work together to broadcast and livestream debates between political leaders. The consortium negotiates the terms of the debates with political parties. Debates commissioner — For 2019, there is a Leaders' Debates Commission, established by the federal government, that will plan and hold two leaders debates, one in English and one in French, in early to mid-October. It is worth noting the commission will contract an organization, or a group of organizations to plan and run the debates.\n",
            "\"The digital currency is headed to new record highs, says Tom Lee, co-founder, managing director and head of research at Fundstrat Global Advisors - but there's a catch some cryptocurrency investors may not be expecting.\"\"Bitcoin has kind of stalled recently because the macro outlook has stalled. I think, in a world without trend, bitcoin doesn't go up,\"\" Lee said Thursday on CNBC's \"\"Fast Money.\"\" \"\"The next big catalyst, I think, is a decisive breakout in the equity markets, because I think once equities break to an all-time high, bitcoin becomes a risk-on asset.\"\"In other words, according to Lee, as stocks go, so goes bitcoin - at least for now.\"\"If markets make a new all-time high and we see central banks still supportive, it's kind of good for liquidity, so there's ... liquidity going into bitcoin,\"\" Lee said. \"\"More importantly, if there's an interest in acquiring some volatility, that's where you're going to see people buying bitcoin.\"\"With Lee expecting the S&P 500 to climb to 3,125 or higher by year-end, that could mean a major rally is in the cards for the increasingly volatile digital currency. Bitcoin reached an all-time high of $20,089 in late 2017, according to CoinBase.\"\n",
            "Amazon is said to be developing a new payment system that allows customers to pay simply by waving their hand.The online retail giant is testing scanners that use biometric technology to identify people by the shape and size of their hands, with the hope of rolling them out in its Whole Foods stores later this year.Sensors are already being tested by Amazon workers on vending machines in the firm's New York offices, according to the New York Post.\n",
            "The Missing Children Society of Canada is hosting the “MCSC rescu” app on its website, intended to recruit the public to assist law enforcement officials. Through the app, targeted alerts can be sent to anyone signed up to the program when children go missing.“We’re able to share information with the police and the public through easy-to-understand dynamic maps and push alerts to people in specific locations, even down to a street,” Amanda Pick, CEO of the society, said of the application developed by Toronto-based ESRI Canada, a geographical information system provider.“This allows us to find children faster, but we need every single Canadian to help us.”\n",
            "Samsung Electronics' B2B devices and solutions are developed for the way business is being done today. Thanks to an extensive global partnership network and a supply chain that runs from R&D through to network, Samsung's mobile B2B strategy is open, innovative and secure. From the retail, transportation, healthcare and finance industries through to the public service and government sectors, Samsung is paving the way for businesses to stay connected, securely and safely.\n",
            "\"After his usually dazzling Los Angeles Rams offense laid an egg against the New England Patriots in Super Bowl LIII, Sean McVay didn't want his players to focus on one bad performance in an otherwise outstanding season.He wanted them to focus on three bad performancesAs part of the Rams' offseason review, the coaching staff made the offense review and study three of their four losses from last season -- the loss to New England, and the early-December losses to the Bears and Eagles. The Rams' offense averaged 30.8 points in 2018 -- second only to the Chiefs -- but only 10.7 in those three losses. (Their other loss was a 45-35 loss to the Saints that, presumably, the defense had to rewatch a few times.)\"\"Just wanted to find different things they did that challenged us that other teams didn't do,\"\" wide receiver Robert Woods told me. \"\"Just try and find as many little details that we could improve on to make our offense adaptable to beat anyone we play.\"\"\"\n",
            "The federal election is officially underway, and that means more Canadians will be moving online to discuss, debate and prepare for the vote.But they'll be stepping into an environment that's been embroiled in the campaign for months, with messaging that ranges from disinformation to good old-fashioned politicking.Here's a look at some of the major players online, the kind of messages they're sharing and what voters can expect online over the next five weeks.\n",
            "\"President Donald Trump explains he wasn't seeing eye-to-eye with ousted hawkish national security adviser John Bolton. The sudden shake-up comes as the president faces pressing decisions on difficult foreign policy issues.John Bolton wasted no time getting back in the political game Friday, just a few days after being ousted as President Donald Trump’s National Security Adviser.Bolton has resumed his old job as the head of two political action committees, the John Bolton PAC and John Bolton Super PAC, announcing that he would be donating $10,000 to five Republican incumbent re-election campaigns for 2020.These include Sens. Tom Cotton (R-Ark.), Cory Gardner (R-Colo.) and Thom Tillis (R-N.C.) and Reps. Adam Kinzinger (R-Ill.) and Lee Zeldin (R-N.Y.).The website reads, \"\"The John Bolton PAC and John Bolton Super PAC seek a strong, clear, and dependable US national security policy, resting on constancy and resolve.”“The experience that these incumbent members of Congress have provides them with a remarkable understanding and knowledge of the threats we face from international terrorism and rogue regimes such as Iran and North Korea,” the statement continues.Trump fired Bolton, his third national security adviser, on Tuesday, saying the two “disagreed strongly” on foreign policy matters. Bolton, however, contradicted Trump's characterization of his departure, writing in a tweet minutes after the president's that he offered to resign.Bolton had temporarily suspended his political activity during his time at the White House.\"\n",
            "\"\"\"This could be the team I need,\"\" Romelu Lukaku said. Sitting in a conference room in Porta Nuova, Milan's emerging business district, he was making the case that Football Club Internazionale Milano was the ideal setting for the resurrection of his career. \"\"There's the love I have for this area,\"\" he said. \"\"The love that I have for Inter. And it was the perfect moment for me to leave England. I didn't want to be there anymore.\"\"It's not exactly coincidental that the club is counting on Lukaku, who spent the past two seasons struggling at Manchester United, to inspire its own revival. These are hard times for Inter, which won a Champions League trophy in 2010 to cap a five-year run of Serie A titles in 2010, but hasn't finished higher than fourth since then. Worse than that, despite a steadfast fan base that continues to nearly fill San Siro, one of Europe's largest stadiums, week after week, Inter has faded into international irrelevance. By winning each of the past eight scudetti and signing Cristiano Ronaldo, Juventus is the Italian team that matters at the moment.\"\n",
            "\"The Tesla pickup truck, described by Elon Musk as \"\"the coolest car I've ever seen,\"\" is now looking at a November reveal at the earliest, according to a tweet from the Tesla CEO. The science-fiction inspired electric pickup truck had been expected to arrive this summer, or October at the latest, based on previous statements made by the notoriously optimistic Musk.Beyond an early concept image of a pickup shown at the unveiling of the Tesla Semi in 2017 and an image tweeted in May, little is known about the Tesla pickup truck. Musk described it as follows in a Recode interview with Kara Swisher last year:\"\"It's gonna be like a really futuristic-like cyberpunk, \"\"Blade Runner\"\" pickup truck. It's gonna be awesome, it's gonna be amazing. This will be heart-stopping. It stops my heart. It's like, oh, it's great.\"\"\"\n",
            "“I’m afraid we will lose some Indigenous people, Indigenous voices that voted last time because of that and I think that’s a shame,” Campbell says.It’s part of the reason she’s tossed her hat in the ring this election — Campbell is running as the NDP candidate in Waterloo and is not the only Indigenous person to cite Trudeau’s leadership failures as a reason to run.Guy Gallant, a campaign spokesperson for Trudeau, said the the Liberals believe Canada’s most important relationship is with Indigenous people and that renewing that relationship and working to close “unacceptable gaps in outcomes in Indigenous communities” is something the party took “real and measurable action” on during its four years in power.With respect to the Trans Mountain pipeline, Gallant pointed to comments Trudeau made on Sept. 13, noting that “a better future” includes partnership with Indigenous people, not just consultation.“That’s why we are moving forward on proposals to allow indigenous communities and indigenous investors to purchase the Trans Mountain pipeline expansion, but that’s why at the same time we’re listening very carefully to the indigenous communities who have concerns,” Trudeau said.\n",
            "\"Scheer is where Trudeau was, trying to contrast the Liberal leader with what a Conservative-led government would deliver: namely a more muscular presence on the world stage.He pledges a get-tough approach to China, saying he'd sue China at the WTO for blocking Canadian canola, end Ottawa's $200 million investment in a Beijing-based Asian Infrastructure Investment Bank (that all our allies except the U.S. have supported), and ban Chinese telecom giant Huawei from participating in Canada's 5G wireless network. He wants to join the U.S. in a continental missile defence system.But while Conservatives slammed Trudeau for his \"\"virtue signalling\"\" pursuit of gender and Indigenous rights guarantees, Scheer says the party will nevertheless support the newly renegotiated NAFTA when it comes for a ratification vote in Parliament.Roland Paris, a University of Ottawa professor and a former Trudeau adviser on foreign policy, says when it comes to differences between Conservatives and Liberals on a wide range of trade, defence and security matters, there is less than meets the eye.Both say they will aim to shore up Canada's international alliances, diversify trade, and identify their solutions as pragmatic, but no party is articulating an isolationist position, for example a Brexit approach, he notes.And all illustrate a \"\"deep-seated openness to the world\"\" and a desire to engage the world that has become central to Canada's identity.So far, Paris says, Scheer seems more open than Harper to international alliances. Scheer said he'd look to boost ties with Canada's \"\"Five Eyes\"\" partners – the U.S., U.K., Australia and New Zealand – and with other \"\"confident\"\" and \"\"like-minded nations\"\" in Asia and Africa and South America.Along with China, Paris says, the Scheer-led Conservatives will undoubtedly highlight different stances on Israel, Iran, climate change and religious freedom.\"\n",
            "When Japanese Prime Minister Shinzo Abe met dozens of African leaders and business executives at the Tokyo International Conference on African Development (TICAD) in Yokohama late last month, two things were clear.First, Tokyo would take on China head to head in resource-rich Africa, where Beijing already has the upper hand in development lending and trade.China is Africa’s biggest trading partner, with two-way trade growing twentyfold in the past two decades to US$204 billion last year, according to China’s Commerce Ministry.China’s rapidly growing trade with African countries has jolted Japan, whose total with the continent is less than 10 per cent of China’s, according to the Japan External Trade Organisation.Second, Japan, the world’s third-biggest economy behind the United States and China, plans to take its battle with Beijing for East Asian supremacy to the doorstep of the United Nations Security Council.In Yokohama, Japanese officials sought African countries’ support for its push for reforms at the council, including getting Japan, Germany, Brazil, India and other nations added as permanent members.Winning permanent membership on the body would allow those countries to wield veto power just like the present five permanent members – China, Britain, France, the United States and Russia.Besides the five permanent members, the council has 10 non-permanent members that serve two-year terms.\n",
            "A team from AI pharma startup Insilico Medicine, working with researchers at the University of Toronto, took 21 days to create 30,000 designs for molecules that target a protein linked with fibrosis (tissue scarring). They synthesized six of these molecules in the lab and then tested two in cells; the most promising one was tested in mice. The researchers concluded it was potent against the protein and showed “drug-like” qualities. All in all, the process took just 46 days. The research was published in Nature Biotechnology this week.The system examines previous research and patents for molecules known to work against the drug target, prioritizing new structures that could be synthesized in the lab. It’s similar to what a human chemist might do to seek new therapies—just much faster.Although the research looks promising, it’s still very much a proof of concept. We’re a long way from AI-designed drugs being created, let alone sold to patients.\n",
            "Timing is everything while discussing a topic as constantly in-flux as restricted free agent (RFA) signings this summer. This article is being written directly after Mitch Marner signed his six-year, $65.3-million contract extension with the Toronto Maple Leafs on Sept. 13th. Every idea presented in this article could look completely ridiculous in a matter of weeks, days or even hours.With that caveat out of the way, here's one thing we can all agree on. For a certain caliber of NHL player, the RFA bridge deal is dead. It has slowly eroded over the years, as teams became more desperate to lock down their young core players at the peak of their careersNo longer will a two or three-year, $15-million bridge deal suffice before signing a massive extension. With stars like Auston Matthews and Marner receiving $10-plus million a year, there's no reason to believe that other RFAs of their caliber are not looking for a similar contract.Under normal circumstances, trading a player like Point would be blasphemy, as 90-point scorers under the age of 25 are a rare commodity in the NHL. However, if the Lightning simply can't reach a deal with him, then a trade may be their only course of action.The problem is, projecting the value of an RFA likely demanding a high-cost contract is difficult. The number of teams who could afford to take on a $10 million extension is limited, and the ones that could may not be willing to part with significant assets to do so.\n",
            "How will the Titans' wide receivers match up against those Colts cornerbacks? Rookies A.J. Brown and Rock Ya-Sin are two physical players, setting up for a fun battle, while Adam Humphries versus Kenny Moore II is a duel of cat-quick players. Perhaps the best one-on-one for Tennessee will be Corey Davis against Pierre Desir. The Titans will not have more than two sacks. Tennessee sacked Browns quarterback Baker Mayfield five times (and intercepted him three times) in Week 1. But the Colts have a better offensive line, as they limited Joey Bosa, Melvin Ingram and the rest of the Chargers' defense to just two sacks in Week 1\n",
            "I used to think that you had to pay big money for a decent oscilloscope, but the DS212 proved me wrong. It is a very capable 2-channel oscilloscope that is handy for diagnosing problems with low-voltage electrical gadgets, good up to 40 Volts.Instructions are a bit scant, so getting to know how to use it can be a bit of an adventure, Google is your friend, but once you have the basics down, it is pretty straightforward.A staple of my repair kit.\n",
            "\"Congressional Democratic leaders warned President Donald Trump on Sunday that any proposal on gun control must include a House-passed bill to expand background checks for gun purchases — or else risk no legislation at all.In a joint statement, House Speaker Nancy Pelosi and Senate Democratic leader Chuck Schumer said they spoke Sunday morning by phone with Trump, who planned to announce as soon as this week what measures he supported.Pelosi, D-Calif., and Schumer, D-N.Y., said they made clear that any proposal lacking the House legislation \"\"will not get the job done\"\" by leaving dangerous loopholes.\"\"We know that to save as many lives as possible, the Senate must pass this bill and the president must sign it,\"\" they said.A White House spokesman, Judd Deere, confirmed that Trump spoke with the Democratic leaders at their request and indicated to them a desire to find a \"\"bipartisan legislative solution\"\" but made no commitments.\"\"The conversation was cordial,\"\" Deere said. \"\"The president reiterated his commitment for his administration to continue work on these issues.\"\"\"\n",
            "Manchester United earned its first win in over a month in beating Leicester 1-0 thanks to an early Marcus Rashford penalty on Saturday.United lost one and drew two of its last three English Premier League games since beating Chelsea 4-0 on the opening day, but seized the lead early against Leicester.\n",
            "\"Technology and AI are increasingly being used to improve our lives, especially in the medical field. Sometimes it's even better than the doctors themselves.Now, researchers at the University of Oxford have used machine learning to help estimate the health of arteries and have developed a new biomarker to predict heart disease, and prevent future heart attacks. The researchers claim it can identify people at risk five years before it strikes. The typical procedure for those with chest pain is to conduct CCTA or coronary CT angiogram — an imaging test to check the arteries. \"\"If there is no significant narrowing of the artery, which accounts for about 75 per cent of scans, people are sent home, yet some of them will still have a heart attack at some point in the future,\"\" the press release claims.\"\n",
            "Here are more weird gadgets that actually turned out to be useful.The Philips Somneo is A smartphone-enabled sunrise alarm clock and therapy lamp that also has built-in sensors to measure your bedroom's temperature, noise, light and humidity levels, and can make suggestions to help you get a better night's sleep.Fiberglass Scratch Brush.Gone are the days of using a screwdriver or knife to scrape corrosion off battery terminals. The fiberglass scratch brush makes short work of cleaning electrical terminals that have corroded as a result of leaky batteries.  A must for any repair kit.Another interesting one, the name is pretty self-explanatory in this one, these USB rechargeable AA and AAA batteries are super-useful in things like computer peripherals or remote controls. Just make sure someone doesn't toss the dead ones into the recycling!This is it for the three gadgets we have today, let us know if you would like to hear more.\n",
            "The trucking industry drew in revenues of $796 billion in 2018, with trucks moving 71% of the nation's freight, according to the American Trucking Association, a trade group. Compare that to the global ride-hailing market, which according to Allied Market Research, was valued at just $36 billion in 2017.Uber is now a player in this market with Uber Freight. Uber Freight launched in 2017, and the program has since expanded to 48 U.S. states, as well as the Netherlands and Germany. Uber says thousands of shippers and almost half a million truck drivers currently\n",
            "Kyle Dubas was smiling like he had won the Stanley Cup.But it should have been Mitch Marner with the Cheshire Cat-like grin.He was the winner on this Saturday afternoon. The winner by knockout or unanimous decision. You take your pick.The deal is done and Marner will be paid $65+ million over the next six years — which makes sense if he was a better player than Nikita Kucherov in Tampa or Brad Marchand in Boston.Which he may be one day but just hasn’t been yet.Kucherov is the NHL’s most valuable player and leading scorer. He’ll earn $1 million a year less than Marner with the Lightning. Marchand, older and more accomplished than Marner, will be paid $6.1 million by the Boston Bruins, a whole $4 million less than Marner comes in at.And the two teams that finished ahead of the Leafs in the Atlantic Division have their best forwards all signed up under far more economic circumstances than Toronto finds itself in.\n",
            "During the 2015 federal election, Liberal Leader Justin Trudeau coasted to victory in part thanks to Indigenous voters determined to evict former prime minister Stephen Harper and his Conservatives from office.Lori Campbell, a two-spirit Cree-Métis woman from the Sixties Scoop generation who is the director of the Shatitsirótha’ Waterloo Indigenous Student Centre at St. Paul’s University College, was one of many drawn in by Trudeau’s sunny ways.And yet, she says, the last four years have been something beyond disheartening.“It’s another one of those things that happen to people who don’t usually have a voice,” Campbell says.It was not one moment, she says, but a series of moments — including the issues that plagued the MMIWG inquiry — that solidified in 2018 when Trudeau’s government bought a pipeline for $4.5 billion and then defended his government’s environmental record.\n",
            "\"Now, physicists from MIT and elsewhere have \"\"heard\"\" the ringing of an infant black hole for the first time, and found that the pattern of this ringing does, in fact, predict the black hole's mass and spin, which is more evidence that Einstein was right all along.The findings, published today in Physical Review Letters, also favor the idea that black holes lack any sort of \"\"hair\"\", which is a metaphor referring to the idea that black holes, according to Einstein's theory, should exhibit just three observable properties: mass, spin, and electric charge. All other characteristics, which the physicist John Wheeler termed \"\"hair,\"\" should be swallowed up by the black hole itself, and would therefore be unobservable.The team's findings today support the idea that black holes are, in fact, hairless. The researchers were able to identify the pattern of a black hole's ringing, and, using Einstein's equations, calculated the mass and spin that the black hole should have, given its ringing pattern. These calculations matched measurements of the black hole's mass and spin made previously by others.If the team's calculations deviated significantly from the measurements, it would have suggested that the black hole's ringing encodes properties other than mass, spin, and electric charge, which would have been tantalizing evidence of physics beyond what Einstein's theory can explain. But as it turns out, the black hole's ringing pattern is a direct signature of its mass and spin, giving support to the notion that black holes are bald-faced giants, lacking any extraneous, hair-like properties.\"\n",
            "You do criticize the Obama Administration, though, particularly the decision to withdraw from Iraq. You also criticize former Vice President Joe Biden, the leading Democratic candidate for President. So how do you square that?With the Obama Administration I talked about the policy. I don’t criticize President Obama politically, I criticize a policy decision that was taken in contravention of the advice of the intelligence community that said if we pull everyone out, if we back al-Malaki who did not, whose party did not have the majority of the votes, then we were going to end of having to go back in. And sure enough, that’s what happened. And the Vice President at that time was Biden. Remember, the book came out, we finally got it done last April I think, I think the first of May was my deadline at that Random House laid on me. And we turned it in.Where was Biden at that point as a nominee? I don’t even remember. And so I’m writing about history here. And I think that’s a legitimate policy and strategy point that an officer can make.\n",
            "Barcelona s club president has confirmed that Lionel Messi would have the right to leave the club at the end of this season, as stipulated in his contract.Spanish newspaper El Pa s reported Thursday that Messi s current contract with Barcelona includes the option for the soccer great to unilaterally end his stay in the summer of 2020.Club president Josep Bartomeu said late Friday that  Leo Messi has a contract through 2020-21, but before that last season the player could leave Barca. Bartomeu, however, said he was confident that the club s all-time leading scorer would stay with the team  until 2021 and beyond. Messi, 32, has scored 603 goals in 687 matches for Barcelona since his debut in 2004. He has helped it win 34 titles, including four Champions League trophies and 10 Spanish leagues.The Argentine has repeatedly said he is happy to play for the Spanish champions.\n",
            "Neymar's return to PSG on Saturday brought boos for much of the match, but by the 90th minute you could hear some cheers thanks to a bit of magic. Taking on Strasbourg and struggling to do much of anything, PSG won 1-0 thanks to a last-minute goal from, you guessed it, Neymar.The Brazilian scored a ridiculous bicycle kick off a cross to seal the win and possibly win back some of the hearts from an upset fan base\n",
            "Cheadle didn’t say where he’ll run, but Federal Election Commission records show he’s run four times before in California’s 1st Congressional District.Trump’s blatant displays of racism have been a cornerstone of his presidency and campaign.In less than three years, Trump has suggested that a deadly white supremacist rally had “some very fine people on both sides,” inspired violence by continuing to slur immigrants as criminals and rapists, and launched a travel ban targeting Muslims.He also singled out four Democratic lawmakers, all of whom were women of color, in a feud earlier this year, urging them to “go back and help fix the totally broken and crime-infested places from which they came.”\n",
            "Two University of Hawaii at Manoa researchers have identified and corrected a subtle error that was made when applying Einstein's equations to model the growth of the universe.Physicists usually assume that a cosmologically large system, such as the universe, is insensitive to details of the small systems contained within it. Kevin Croker, a postdoctoral research fellow in the Department of Physics and Astronomy, and Joel Weiner, a faculty member in the Department of Mathematics, have shown that this assumption can fail for the compact objects that remain after the collapse and explosion of very large stars.For 80 years, we've generally operated under the assumption that the universe, in broad strokes, was not affected by the particular details of any small region, said Croker. It is now clear that general relativity can observably connect collapsed stars, which are regions the size of Honolulu, to the behavior of the universe as a whole, over a thousand billion billion times larger.Croker and Weiner demonstrated that the growth rate of the universe can become sensitive to the averaged contribution of such compact objects. Likewise, the objects themselves can become linked to the growth of the universe, gaining or losing energy depending on the objects' compositions. This result is significant since it reveals unexpected connections between cosmological and compact object physics, which in turn leads to many new observational predictions.One consequence of this study is that the growth rate of the universe provides information about what happens to stars at the end of their lives. Astronomers typically assume that large stars form black holes when they die, but this is not the only possible outcome. In 1966, Erast Gliner, a young physicist at the Ioffe Physico-Technical Institute in Leningrad, proposed an alternative hypothesis that very large stars should collapse into what could now be called Generic Objects of Dark Energy, or GEODEs. These appear to be black holes when viewed from the outside but, unlike black holes, they contain Dark Energy instead of a singularity.In 1998, two independent teams of astronomers discovered that the expansion of the Universe is accelerating, consistent with the presence of a uniform contribution of Dark Energy. It was not recognized, however, that GEODEs could contribute in this way. With the corrected formalism, Croker and Weiner showed that if a fraction of the oldest stars collapsed into GEODEs, instead of black holes, their averaged contribution today would naturally produce the required uniform Dark Energy.\n",
            "\"Top 2020 Democratic contenders Kamala Harris, Elizabeth Warren, Bernie Sanders, Beto O'Rourke, and Julian Castro announced on Sunday that Supreme Court Associate Justice Brett Kavanaugh \"\"must be impeached,\"\" after a new, uncorroborated and disputed allegation of sexual misconduct against Kavanaugh surfaced in a weekend New York Times piece.The revitalized, longshot push to get Kavanaugh removed from the high court comes as Democrats' apparent effort to impeach President Trump has largely stalled. Trump, for his part, suggested Sunday that Kavanaugh should sue for defamation.The Times piece by Robin Pogrebin and Kate Kelly, adapted from their forthcoming book, asserted that a Kavanaugh classmate, Clinton-connected nonprofit CEO Max Stier, \"\"saw Mr. Kavanaugh with his pants down at a different drunken dorm party, where friends pushed his penis into the hand of a female student.\"\"The Times did not mention Stier's work as a Clinton defense attorney, or Stier's legal battles with Kavanaugh during the Whitewater investigation, and simply called him a \"\"respected thought leader.\"\"\"\n",
            "After 154 all-purpose yards in Week 1, Chargers running back Austin Ekeler will face a good defensive front in Detroit. If Ekeler can shake loose against the Lions, it could be a long day for Detroit because it would open up even more passing lanes for Philip Rivers. -- Michael RothsteinJoey Bosa records three sacks. The Chargers should heat up the pass rush against a Lions offensive line that allowed three Matthew Stafford sacks in the team's season opener against the Cardinals. Rivers posted a Total QBR of 80 on the road last season, the second-best number in the NFL. And the Lions lost four of their final five home games last season and scored 16 points or fewer in each of the four losses.\n",
            "Spotify is adding the ability to share whatever it is you're listening to with a snap on Snapchat - long after other platforms like Instagram already got this same type of integration. So long as Snapchat is installed on the same device you're using Spotify on, you'll now see it appear in Spotify's share menu\n",
            "Leading off as the designated hitter in Friday's contest against the AL East-leading New York Yankees, Bichette went 3-for-5, logging an all-important walk-off home run in the 12th. Bichette, at 21 years and 192 days old, became the youngest Blue Jay in franchise history to hit a walk-off homer, and he apparently felt it coming.Prior to the at-bat, Bichette reportedly told teammate Charlie Montoyo that he felt good about his chances going against a lefty.It was Zombie Night at the Rogers Centre and, fittingly, it took multiple spurts of life for the Blue Jays to come out on top.Leading 3-0 through the first four innings, Toronto had control. But the Yankees took the lead and all of the momentum with a five-run top of the fifth.This killed the Blue Jays   for the time being.After responding with only a single run in the fifth, the Blue Jays still trailed, but only until the seventh inning when they knotted the game up at 5-all. Working Richard Urena around the bases took just about every tool available: a single, a walk, a fielder's choice and a sacrifice fly brought in the tying run.The Jays then had an opportunity to end the game in the ninth with Bichette standing on third, but were unable to finish.In extra innings, the Blue Jays came back to life.Three pitches into the at-bat, Bichette launches one estimated at 390 feet over the center-field wall.\n",
            "\"Google is changing its news search algorithms again, in a move that's sure to annoy everybody. Today's announcement is that the company is going to try to emphasize \"\"original reporting,\"\" which it will \"\"elevate\"\" in its search results. To do so, it has distributed new instructions to its cadre of 10,000+ human reviewers, whose feedback helps train the Google algorithm that actually delivers search rankings.\"\n",
            "Agricultural biotechnology is a branch of agriculture in which scientific techniques and tools that are used to modify plants for better yield. Agricultural biotechnology is also known as agritech, where plant DNAs are generally modified using different techniques. The use of agricultural biotechnology benefits the farmers as well as for the environment.Global Agricultural Biotechnology Market Report focuses on the major drivers and restraints for the key players. This Research Report also provides granular analysis of the market share, segmentation, revenue forecasts and geographic regions of the market. The Global Agricultural BiotechnologyMarket Research Rep.This report focuses on the Agricultural Biotechnologyin global market, especially in North America, Europe, Asia-Pacific, and LAMEA. This report classifies the market based on manufacturers, regions, type, and application. Moreover, the competitive scenario in different areas is outlined in the report to assist leading market players, new entrants, and stakeholders to determine emerging economies.The Agricultural Biotechnologymarket study is a well-researched report encompassing a detailed analysis of this industry with respect to certain parameters such as the product capacity as well as the overall market remuneration. The report enumerates details about production and consumption patterns in the business as well, in addition to the current scenario of the Agricultural Biotechnologymarket and the trends that will prevail in this industry.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxtQ28p4JGaL",
        "colab_type": "code",
        "outputId": "e6b938fa-023b-4ca5-d4f8-4bf385555d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Beginning Predictions!')\n",
        "current_time = datetime.now()\n",
        "\n",
        "predict_input_fn = input_fn_builder(features=test_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "predictions = estimator.predict(predict_input_fn)\n",
        "print(\"Prediction took time \", datetime.now() - current_time)\n",
        "\n",
        "probabilities=[]\n",
        "for (i, prediction) in enumerate(predictions):\n",
        "  preds = prediction[\"probabilities\"]\n",
        "  probabilities.append(preds)\n",
        "\n",
        "for i in range(len(probabilities)):\n",
        "  for j in range(len(probabilities[0])):\n",
        "    if probabilities[i][j]>0.3:\n",
        "      probabilities[i][j]=1\n",
        "    else:\n",
        "      probabilities[i][j]=0\n",
        "print(probabilities)\n",
        "\n",
        "def evaluate_score(Y_test,predict): \n",
        "    \"\"\"\n",
        "    Y_test: array\n",
        "    predict: array\n",
        "    \"\"\"\n",
        "    Y_test = np.array(Y_test)\n",
        "    Y_test = Y_test.astype(np.int32)\n",
        "   \n",
        "    predict = np.array(predict)\n",
        "    predict = predict.astype(np.int32)\n",
        "    temp = Y_test ^ predict\n",
        "    each_acc = 1-np.sum(temp,axis=0)/len(Y_test)\n",
        "    loss = hamming_loss(Y_test,predict)\n",
        "    #print(\"Hamming_loss : {}\".format(loss*100))\n",
        "    accuracy = accuracy_score(Y_test,predict)\n",
        "    #print(\"Accuracy : {}\".format(accuracy*100))\n",
        "    return loss*100, accuracy*100, each_acc\n",
        "  \n",
        "    \n",
        "test_labels=[]\n",
        "for (i, line) in enumerate(test_data):    \n",
        "  labels = tokenization.convert_to_unicode(line[0])\n",
        "  labels = labels.split(\", \")   #format: list  ['a'] or ['a','b']\n",
        "  labels = Multi_hot_label(labels,label_list)\n",
        "  test_labels.append(labels)\n",
        "\n",
        "h_loss, acc, each_acc= evaluate_score(np.array(probabilities),np.array(test_labels))\n",
        "print (\"Hamming_loss (%) : {}\".format(h_loss))\n",
        "print (\"Accuracy (%) : {}\".format(acc))\n",
        "\n",
        "\n",
        "#each_acc = evaluate_score(test_labels,probabilities)\n",
        "for i in range(len(label_list)):\n",
        "    print(\"bert, label:{}, acc:{}\".format(label_list[i],each_acc[i]))\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Predictions!\n",
            "Prediction took time  0:00:00.000236\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?, 13)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:num_labels:13;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 13), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 13), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 13), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/My Drive/insight_project/working/output/model.ckpt-437\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
            "Hamming_loss (%) : 1.9230769230769231\n",
            "Accuracy (%) : 83.33333333333334\n",
            "bert, label:Baseball, acc:1.0\n",
            "bert, label:Basketball, acc:1.0\n",
            "bert, label:Canadian National, acc:0.9166666666666666\n",
            "bert, label:Company, acc:0.9722222222222222\n",
            "bert, label:Finance, acc:1.0\n",
            "bert, label:Football, acc:1.0\n",
            "bert, label:Gadgets, acc:1.0\n",
            "bert, label:General Tech (Various buzzwords), acc:1.0\n",
            "bert, label:Hockey, acc:1.0\n",
            "bert, label:International, acc:0.9166666666666666\n",
            "bert, label:Science, acc:1.0\n",
            "bert, label:Soccer, acc:1.0\n",
            "bert, label:US National, acc:0.9444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjHW8-4Tj896",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b0f2c6b-9768-474f-88a8-53b7f27d6a94"
      },
      "source": [
        "print(\"predictions:{}\".format(np.array(probabilities)))\n",
        "print(\"labels:{}\".format(np.array(test_labels)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions:[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "labels:[[0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}